{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = inception_v3.InceptionV3(include_top=False,weights='imagenet')\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the placeholder for the input images\n",
    "input_img = model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Activation object at 0x000001C3BA99AEB8>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'activation_94'\n",
    "print(layer_dict[layer_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter 0\n",
      "Current loss value: 16.474705\n",
      "Current loss value: 74.17623\n",
      "Current loss value: 109.6045\n",
      "Current loss value: 145.6452\n",
      "Current loss value: 169.97594\n",
      "Current loss value: 198.21436\n",
      "Current loss value: 241.28331\n",
      "Current loss value: 269.17502\n",
      "Current loss value: 298.92993\n",
      "Current loss value: 337.1813\n",
      "Current loss value: 366.90527\n",
      "Current loss value: 409.5593\n",
      "Current loss value: 444.45963\n",
      "Current loss value: 472.7512\n",
      "Current loss value: 495.36215\n",
      "Current loss value: 505.07642\n",
      "Current loss value: 532.62946\n",
      "Current loss value: 554.2102\n",
      "Current loss value: 590.86536\n",
      "Current loss value: 609.76483\n",
      "Filter 0 processed in 5s\n",
      "Processing filter 1\n",
      "Current loss value: 56.311527\n",
      "Current loss value: 113.63225\n",
      "Current loss value: 154.83752\n",
      "Current loss value: 187.44359\n",
      "Current loss value: 247.26141\n",
      "Current loss value: 277.34167\n",
      "Current loss value: 313.63834\n",
      "Current loss value: 336.5029\n",
      "Current loss value: 362.7242\n",
      "Current loss value: 410.89224\n",
      "Current loss value: 453.0484\n",
      "Current loss value: 491.61096\n",
      "Current loss value: 527.8873\n",
      "Current loss value: 592.3991\n",
      "Current loss value: 654.60675\n",
      "Current loss value: 702.6789\n",
      "Current loss value: 734.36957\n",
      "Current loss value: 708.98914\n",
      "Current loss value: 790.45\n",
      "Current loss value: 711.53784\n",
      "Filter 1 processed in 5s\n",
      "Processing filter 2\n",
      "Current loss value: 0.0\n",
      "Filter 2 processed in 3s\n",
      "Processing filter 3\n",
      "Current loss value: 0.0\n",
      "Filter 3 processed in 3s\n",
      "Processing filter 4\n",
      "Current loss value: 49.07745\n",
      "Current loss value: 93.87154\n",
      "Current loss value: 130.12538\n",
      "Current loss value: 155.85925\n",
      "Current loss value: 194.01048\n",
      "Current loss value: 233.18057\n",
      "Current loss value: 245.10875\n",
      "Current loss value: 230.13985\n",
      "Current loss value: 286.19662\n",
      "Current loss value: 301.28552\n",
      "Current loss value: 294.98245\n",
      "Current loss value: 293.5898\n",
      "Current loss value: 323.4732\n",
      "Current loss value: 335.66727\n",
      "Current loss value: 377.81888\n",
      "Current loss value: 362.68423\n",
      "Current loss value: 409.36145\n",
      "Current loss value: 401.78778\n",
      "Current loss value: 418.5447\n",
      "Current loss value: 456.81357\n",
      "Filter 4 processed in 6s\n",
      "Processing filter 5\n",
      "Current loss value: 0.0\n",
      "Filter 5 processed in 3s\n",
      "Processing filter 6\n",
      "Current loss value: 31.098068\n",
      "Current loss value: 67.67449\n",
      "Current loss value: 98.81908\n",
      "Current loss value: 115.206825\n",
      "Current loss value: 134.93785\n",
      "Current loss value: 164.0861\n",
      "Current loss value: 169.61046\n",
      "Current loss value: 195.91486\n",
      "Current loss value: 216.3353\n",
      "Current loss value: 235.5558\n",
      "Current loss value: 223.87958\n",
      "Current loss value: 270.57355\n",
      "Current loss value: 273.3472\n",
      "Current loss value: 306.87216\n",
      "Current loss value: 304.99435\n",
      "Current loss value: 342.30356\n",
      "Current loss value: 273.99298\n",
      "Current loss value: 362.48904\n",
      "Current loss value: 373.44153\n",
      "Current loss value: 389.07312\n",
      "Filter 6 processed in 6s\n",
      "Processing filter 7\n",
      "Current loss value: 28.628656\n",
      "Current loss value: 70.088615\n",
      "Current loss value: 98.59096\n",
      "Current loss value: 121.51344\n",
      "Current loss value: 134.73045\n",
      "Current loss value: 140.96707\n",
      "Current loss value: 152.55957\n",
      "Current loss value: 139.70673\n",
      "Current loss value: 169.14713\n",
      "Current loss value: 169.94669\n",
      "Current loss value: 163.67534\n",
      "Current loss value: 179.5853\n",
      "Current loss value: 171.86073\n",
      "Current loss value: 175.05037\n",
      "Current loss value: 198.89119\n",
      "Current loss value: 191.52045\n",
      "Current loss value: 217.05205\n",
      "Current loss value: 202.73672\n",
      "Current loss value: 227.55698\n",
      "Current loss value: 224.70064\n",
      "Filter 7 processed in 6s\n",
      "Processing filter 8\n",
      "Current loss value: 0.0\n",
      "Filter 8 processed in 3s\n",
      "Processing filter 9\n",
      "Current loss value: 0.0\n",
      "Filter 9 processed in 3s\n",
      "Processing filter 10\n",
      "Current loss value: 72.86294\n",
      "Current loss value: 118.60604\n",
      "Current loss value: 143.17807\n",
      "Current loss value: 162.65436\n",
      "Current loss value: 181.97371\n",
      "Current loss value: 194.1445\n",
      "Current loss value: 225.57132\n",
      "Current loss value: 244.56512\n",
      "Current loss value: 264.6133\n",
      "Current loss value: 261.90036\n",
      "Current loss value: 251.78366\n",
      "Current loss value: 292.95944\n",
      "Current loss value: 282.57828\n",
      "Current loss value: 306.2085\n",
      "Current loss value: 293.69025\n",
      "Current loss value: 318.27008\n",
      "Current loss value: 346.63098\n",
      "Current loss value: 297.77536\n",
      "Current loss value: 375.0498\n",
      "Current loss value: 363.7818\n",
      "Filter 10 processed in 6s\n",
      "Processing filter 11\n",
      "Current loss value: 161.00497\n",
      "Current loss value: 213.84013\n",
      "Current loss value: 255.49307\n",
      "Current loss value: 273.30264\n",
      "Current loss value: 284.65067\n",
      "Current loss value: 300.30948\n",
      "Current loss value: 304.64456\n",
      "Current loss value: 325.4725\n",
      "Current loss value: 312.19547\n",
      "Current loss value: 338.2361\n",
      "Current loss value: 337.3743\n",
      "Current loss value: 342.2174\n",
      "Current loss value: 359.13306\n",
      "Current loss value: 372.19922\n",
      "Current loss value: 364.18076\n",
      "Current loss value: 390.4296\n",
      "Current loss value: 391.06747\n",
      "Current loss value: 410.75705\n",
      "Current loss value: 407.6395\n",
      "Current loss value: 438.592\n",
      "Filter 11 processed in 6s\n",
      "Processing filter 12\n",
      "Current loss value: 88.92718\n",
      "Current loss value: 140.1441\n",
      "Current loss value: 191.7321\n",
      "Current loss value: 240.55478\n",
      "Current loss value: 263.82025\n",
      "Current loss value: 292.16904\n",
      "Current loss value: 309.2103\n",
      "Current loss value: 332.6575\n",
      "Current loss value: 368.38495\n",
      "Current loss value: 388.62857\n",
      "Current loss value: 393.18832\n",
      "Current loss value: 422.9949\n",
      "Current loss value: 437.48578\n",
      "Current loss value: 460.91174\n",
      "Current loss value: 422.40225\n",
      "Current loss value: 491.50317\n",
      "Current loss value: 511.25287\n",
      "Current loss value: 507.61932\n",
      "Current loss value: 558.4589\n",
      "Current loss value: 583.8996\n",
      "Filter 12 processed in 6s\n",
      "Processing filter 13\n",
      "Current loss value: 86.07507\n",
      "Current loss value: 121.64978\n",
      "Current loss value: 143.62375\n",
      "Current loss value: 169.4314\n",
      "Current loss value: 222.10704\n",
      "Current loss value: 278.1861\n",
      "Current loss value: 340.02634\n",
      "Current loss value: 394.3966\n",
      "Current loss value: 450.15756\n",
      "Current loss value: 486.30515\n",
      "Current loss value: 478.4113\n",
      "Current loss value: 539.74756\n",
      "Current loss value: 591.5077\n",
      "Current loss value: 623.9147\n",
      "Current loss value: 688.3606\n",
      "Current loss value: 733.3326\n",
      "Current loss value: 749.078\n",
      "Current loss value: 813.44305\n",
      "Current loss value: 871.1509\n",
      "Current loss value: 911.1918\n",
      "Filter 13 processed in 6s\n",
      "Processing filter 14\n",
      "Current loss value: 50.066544\n",
      "Current loss value: 92.73543\n",
      "Current loss value: 128.26085\n",
      "Current loss value: 172.739\n",
      "Current loss value: 217.42688\n",
      "Current loss value: 263.16214\n",
      "Current loss value: 295.4492\n",
      "Current loss value: 309.73242\n",
      "Current loss value: 311.72968\n",
      "Current loss value: 363.1259\n",
      "Current loss value: 382.1244\n",
      "Current loss value: 408.41153\n",
      "Current loss value: 403.07214\n",
      "Current loss value: 448.39978\n",
      "Current loss value: 398.95102\n",
      "Current loss value: 483.8012\n",
      "Current loss value: 491.20987\n",
      "Current loss value: 526.9176\n",
      "Current loss value: 501.90833\n",
      "Current loss value: 562.8675\n",
      "Filter 14 processed in 6s\n",
      "Processing filter 15\n",
      "Current loss value: 120.799065\n",
      "Current loss value: 177.41591\n",
      "Current loss value: 215.77126\n",
      "Current loss value: 247.11322\n",
      "Current loss value: 257.65723\n",
      "Current loss value: 279.77533\n",
      "Current loss value: 276.12726\n",
      "Current loss value: 311.21127\n",
      "Current loss value: 337.95486\n",
      "Current loss value: 346.92386\n",
      "Current loss value: 343.11612\n",
      "Current loss value: 367.44125\n",
      "Current loss value: 369.6806\n",
      "Current loss value: 394.1566\n",
      "Current loss value: 402.05588\n",
      "Current loss value: 429.43915\n",
      "Current loss value: 397.21194\n",
      "Current loss value: 465.19254\n",
      "Current loss value: 455.27408\n",
      "Current loss value: 470.22223\n",
      "Filter 15 processed in 6s\n",
      "Processing filter 16\n",
      "Current loss value: 0.0\n",
      "Filter 16 processed in 4s\n",
      "Processing filter 17\n",
      "Current loss value: 0.0\n",
      "Filter 17 processed in 4s\n",
      "Processing filter 18\n",
      "Current loss value: 0.0\n",
      "Filter 18 processed in 5s\n",
      "Processing filter 19\n",
      "Current loss value: 0.0\n",
      "Filter 19 processed in 4s\n",
      "Processing filter 20\n",
      "Current loss value: 0.0\n",
      "Filter 20 processed in 4s\n",
      "Processing filter 21\n",
      "Current loss value: 40.95749\n",
      "Current loss value: 99.56758\n",
      "Current loss value: 163.1453\n",
      "Current loss value: 241.89914\n",
      "Current loss value: 309.15616\n",
      "Current loss value: 362.57877\n",
      "Current loss value: 422.89478\n",
      "Current loss value: 472.8039\n",
      "Current loss value: 535.22974\n",
      "Current loss value: 577.86346\n",
      "Current loss value: 572.0711\n",
      "Current loss value: 632.39685\n",
      "Current loss value: 675.3878\n",
      "Current loss value: 724.4579\n",
      "Current loss value: 770.67834\n",
      "Current loss value: 831.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 845.4257\n",
      "Current loss value: 917.26373\n",
      "Current loss value: 989.36835\n",
      "Current loss value: 1046.9431\n",
      "Filter 21 processed in 7s\n",
      "Processing filter 22\n",
      "Current loss value: 56.72976\n",
      "Current loss value: 111.66561\n",
      "Current loss value: 148.40736\n",
      "Current loss value: 196.43314\n",
      "Current loss value: 245.8677\n",
      "Current loss value: 276.01328\n",
      "Current loss value: 313.52792\n",
      "Current loss value: 349.58386\n",
      "Current loss value: 367.94675\n",
      "Current loss value: 399.80396\n",
      "Current loss value: 433.96793\n",
      "Current loss value: 439.40976\n",
      "Current loss value: 472.47794\n",
      "Current loss value: 426.09256\n",
      "Current loss value: 505.96515\n",
      "Current loss value: 462.32928\n",
      "Current loss value: 553.1442\n",
      "Current loss value: 548.0912\n",
      "Current loss value: 598.45465\n",
      "Current loss value: 576.9035\n",
      "Filter 22 processed in 7s\n",
      "Processing filter 23\n",
      "Current loss value: 0.0\n",
      "Filter 23 processed in 5s\n",
      "Processing filter 24\n",
      "Current loss value: 0.0\n",
      "Filter 24 processed in 5s\n",
      "Processing filter 25\n",
      "Current loss value: 42.28989\n",
      "Current loss value: 87.504005\n",
      "Current loss value: 126.533775\n",
      "Current loss value: 153.4819\n",
      "Current loss value: 195.54286\n",
      "Current loss value: 229.59474\n",
      "Current loss value: 263.05286\n",
      "Current loss value: 292.68146\n",
      "Current loss value: 324.48148\n",
      "Current loss value: 343.97214\n",
      "Current loss value: 360.09125\n",
      "Current loss value: 379.63104\n",
      "Current loss value: 419.07297\n",
      "Current loss value: 453.1118\n",
      "Current loss value: 496.1928\n",
      "Current loss value: 537.4247\n",
      "Current loss value: 593.4676\n",
      "Current loss value: 639.0813\n",
      "Current loss value: 687.0895\n",
      "Current loss value: 715.2062\n",
      "Filter 25 processed in 8s\n",
      "Processing filter 26\n",
      "Current loss value: 0.0\n",
      "Filter 26 processed in 5s\n",
      "Processing filter 27\n",
      "Current loss value: 0.0\n",
      "Filter 27 processed in 5s\n",
      "Processing filter 28\n",
      "Current loss value: 152.14421\n",
      "Current loss value: 218.58081\n",
      "Current loss value: 274.53867\n",
      "Current loss value: 312.0919\n",
      "Current loss value: 318.29468\n",
      "Current loss value: 330.04675\n",
      "Current loss value: 326.68805\n",
      "Current loss value: 363.33014\n",
      "Current loss value: 368.07065\n",
      "Current loss value: 386.5436\n",
      "Current loss value: 393.81387\n",
      "Current loss value: 410.13748\n",
      "Current loss value: 402.29895\n",
      "Current loss value: 434.93878\n",
      "Current loss value: 435.5387\n",
      "Current loss value: 457.34756\n",
      "Current loss value: 471.1725\n",
      "Current loss value: 491.04718\n",
      "Current loss value: 505.97366\n",
      "Current loss value: 530.355\n",
      "Filter 28 processed in 8s\n",
      "Processing filter 29\n",
      "Current loss value: 10.229798\n",
      "Current loss value: 56.631218\n",
      "Current loss value: 101.644066\n",
      "Current loss value: 155.2193\n",
      "Current loss value: 184.09238\n",
      "Current loss value: 211.68802\n",
      "Current loss value: 239.52672\n",
      "Current loss value: 260.75287\n",
      "Current loss value: 286.62967\n",
      "Current loss value: 305.1077\n",
      "Current loss value: 326.56964\n",
      "Current loss value: 314.2422\n",
      "Current loss value: 337.68927\n",
      "Current loss value: 352.74118\n",
      "Current loss value: 380.537\n",
      "Current loss value: 384.4196\n",
      "Current loss value: 398.80365\n",
      "Current loss value: 414.9553\n",
      "Current loss value: 424.70648\n",
      "Current loss value: 420.44824\n",
      "Filter 29 processed in 8s\n",
      "Processing filter 30\n",
      "Current loss value: 0.0\n",
      "Filter 30 processed in 6s\n",
      "Processing filter 31\n",
      "Current loss value: 39.746235\n",
      "Current loss value: 80.16916\n",
      "Current loss value: 97.14318\n",
      "Current loss value: 119.93257\n",
      "Current loss value: 131.96402\n",
      "Current loss value: 150.45227\n",
      "Current loss value: 158.27887\n",
      "Current loss value: 173.10057\n",
      "Current loss value: 173.14406\n",
      "Current loss value: 151.74426\n",
      "Current loss value: 193.25851\n",
      "Current loss value: 184.87682\n",
      "Current loss value: 203.57742\n",
      "Current loss value: 168.23889\n",
      "Current loss value: 213.59862\n",
      "Current loss value: 176.78168\n",
      "Current loss value: 221.88655\n",
      "Current loss value: 196.77843\n",
      "Current loss value: 231.56862\n",
      "Current loss value: 230.8991\n",
      "Filter 31 processed in 9s\n",
      "Processing filter 32\n",
      "Current loss value: 0.0\n",
      "Filter 32 processed in 7s\n",
      "Processing filter 33\n",
      "Current loss value: 3.289165\n",
      "Current loss value: 70.052765\n",
      "Current loss value: 103.47402\n",
      "Current loss value: 121.42414\n",
      "Current loss value: 152.62524\n",
      "Current loss value: 178.76416\n",
      "Current loss value: 172.90016\n",
      "Current loss value: 211.2419\n",
      "Current loss value: 226.49925\n",
      "Current loss value: 225.90257\n",
      "Current loss value: 197.58884\n",
      "Current loss value: 272.72485\n",
      "Current loss value: 275.8962\n",
      "Current loss value: 286.726\n",
      "Current loss value: 290.14832\n",
      "Current loss value: 324.31564\n",
      "Current loss value: 310.58548\n",
      "Current loss value: 326.88943\n",
      "Current loss value: 338.3329\n",
      "Current loss value: 309.39697\n",
      "Filter 33 processed in 10s\n",
      "Processing filter 34\n",
      "Current loss value: 0.0\n",
      "Filter 34 processed in 8s\n",
      "Processing filter 35\n",
      "Current loss value: 0.0\n",
      "Filter 35 processed in 7s\n",
      "Processing filter 36\n",
      "Current loss value: 73.14731\n",
      "Current loss value: 122.071785\n",
      "Current loss value: 152.97246\n",
      "Current loss value: 167.32578\n",
      "Current loss value: 199.04733\n",
      "Current loss value: 236.97316\n",
      "Current loss value: 271.8102\n",
      "Current loss value: 325.7244\n",
      "Current loss value: 381.55728\n",
      "Current loss value: 424.67325\n",
      "Current loss value: 457.91742\n",
      "Current loss value: 498.6109\n",
      "Current loss value: 544.08167\n",
      "Current loss value: 583.26904\n",
      "Current loss value: 617.4871\n",
      "Current loss value: 620.96136\n",
      "Current loss value: 670.6894\n",
      "Current loss value: 664.00085\n",
      "Current loss value: 707.8286\n",
      "Current loss value: 733.1341\n",
      "Filter 36 processed in 10s\n",
      "Processing filter 37\n",
      "Current loss value: 0.0\n",
      "Filter 37 processed in 8s\n",
      "Processing filter 38\n",
      "Current loss value: 0.0\n",
      "Filter 38 processed in 8s\n",
      "Processing filter 39\n",
      "Current loss value: 0.0\n",
      "Filter 39 processed in 8s\n",
      "Processing filter 40\n",
      "Current loss value: 115.21333\n",
      "Current loss value: 185.4488\n",
      "Current loss value: 234.64218\n",
      "Current loss value: 279.08197\n",
      "Current loss value: 308.3317\n",
      "Current loss value: 343.09976\n",
      "Current loss value: 364.42252\n",
      "Current loss value: 382.21396\n",
      "Current loss value: 392.11316\n",
      "Current loss value: 401.20026\n",
      "Current loss value: 425.389\n",
      "Current loss value: 438.06976\n",
      "Current loss value: 419.51688\n",
      "Current loss value: 456.4508\n",
      "Current loss value: 478.38513\n",
      "Current loss value: 486.91116\n",
      "Current loss value: 486.2613\n",
      "Current loss value: 510.75085\n",
      "Current loss value: 513.971\n",
      "Current loss value: 538.5789\n",
      "Filter 40 processed in 11s\n",
      "Processing filter 41\n",
      "Current loss value: 51.691204\n",
      "Current loss value: 74.7238\n",
      "Current loss value: 94.335526\n",
      "Current loss value: 108.8158\n",
      "Current loss value: 119.182106\n",
      "Current loss value: 129.52567\n",
      "Current loss value: 136.32454\n",
      "Current loss value: 150.20337\n",
      "Current loss value: 141.56796\n",
      "Current loss value: 147.49625\n",
      "Current loss value: 152.15996\n",
      "Current loss value: 159.51022\n",
      "Current loss value: 157.76936\n",
      "Current loss value: 173.21132\n",
      "Current loss value: 163.69086\n",
      "Current loss value: 184.19441\n",
      "Current loss value: 167.96991\n",
      "Current loss value: 177.8819\n",
      "Current loss value: 181.42479\n",
      "Current loss value: 190.56842\n",
      "Filter 41 processed in 11s\n",
      "Processing filter 42\n",
      "Current loss value: 22.75345\n",
      "Current loss value: 53.249672\n",
      "Current loss value: 87.36373\n",
      "Current loss value: 107.27578\n",
      "Current loss value: 115.183266\n",
      "Current loss value: 121.228516\n",
      "Current loss value: 130.2685\n",
      "Current loss value: 149.85355\n",
      "Current loss value: 142.68343\n",
      "Current loss value: 175.63934\n",
      "Current loss value: 170.4262\n",
      "Current loss value: 190.45334\n",
      "Current loss value: 178.87865\n",
      "Current loss value: 206.84288\n",
      "Current loss value: 190.79665\n",
      "Current loss value: 223.61002\n",
      "Current loss value: 189.47404\n",
      "Current loss value: 237.69403\n",
      "Current loss value: 224.44969\n",
      "Current loss value: 238.79333\n",
      "Filter 42 processed in 11s\n",
      "Processing filter 43\n",
      "Current loss value: 0.0\n",
      "Filter 43 processed in 8s\n",
      "Processing filter 44\n",
      "Current loss value: 0.0\n",
      "Filter 44 processed in 8s\n",
      "Processing filter 45\n",
      "Current loss value: 29.282999\n",
      "Current loss value: 88.69177\n",
      "Current loss value: 160.52138\n",
      "Current loss value: 220.08728\n",
      "Current loss value: 256.4101\n",
      "Current loss value: 285.55905\n",
      "Current loss value: 256.43228\n",
      "Current loss value: 308.05316\n",
      "Current loss value: 321.1764\n",
      "Current loss value: 325.9236\n",
      "Current loss value: 331.64902\n",
      "Current loss value: 365.65018\n",
      "Current loss value: 343.8035\n",
      "Current loss value: 378.23007\n",
      "Current loss value: 381.11304\n",
      "Current loss value: 385.65576\n",
      "Current loss value: 392.7615\n",
      "Current loss value: 415.41238\n",
      "Current loss value: 417.406\n",
      "Current loss value: 423.521\n",
      "Filter 45 processed in 11s\n",
      "Processing filter 46\n",
      "Current loss value: 0.0\n",
      "Filter 46 processed in 9s\n",
      "Processing filter 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 82.51004\n",
      "Current loss value: 118.79058\n",
      "Current loss value: 152.33417\n",
      "Current loss value: 169.13701\n",
      "Current loss value: 194.32904\n",
      "Current loss value: 222.94429\n",
      "Current loss value: 247.63737\n",
      "Current loss value: 274.50723\n",
      "Current loss value: 300.7542\n",
      "Current loss value: 271.23877\n",
      "Current loss value: 327.53073\n",
      "Current loss value: 333.32367\n",
      "Current loss value: 354.85666\n",
      "Current loss value: 318.58066\n",
      "Current loss value: 384.99814\n",
      "Current loss value: 402.08984\n",
      "Current loss value: 402.1455\n",
      "Current loss value: 375.37332\n",
      "Current loss value: 434.81525\n",
      "Current loss value: 389.19998\n",
      "Filter 47 processed in 12s\n",
      "Processing filter 48\n",
      "Current loss value: 77.43676\n",
      "Current loss value: 120.73792\n",
      "Current loss value: 153.4166\n",
      "Current loss value: 194.05652\n",
      "Current loss value: 229.99329\n",
      "Current loss value: 259.60135\n",
      "Current loss value: 251.62807\n",
      "Current loss value: 307.36783\n",
      "Current loss value: 291.6623\n",
      "Current loss value: 338.0337\n",
      "Current loss value: 350.71164\n",
      "Current loss value: 391.57047\n",
      "Current loss value: 379.81088\n",
      "Current loss value: 439.674\n",
      "Current loss value: 435.51852\n",
      "Current loss value: 471.99838\n",
      "Current loss value: 433.95596\n",
      "Current loss value: 509.95343\n",
      "Current loss value: 523.1186\n",
      "Current loss value: 544.65674\n",
      "Filter 48 processed in 12s\n",
      "Processing filter 49\n",
      "Current loss value: 0.16040505\n",
      "Current loss value: 26.746723\n",
      "Current loss value: 45.69536\n",
      "Current loss value: 71.47354\n",
      "Current loss value: 84.238144\n",
      "Current loss value: 59.864197\n",
      "Current loss value: 95.93723\n",
      "Current loss value: 100.0224\n",
      "Current loss value: 113.12834\n",
      "Current loss value: 117.80477\n",
      "Current loss value: 128.67914\n",
      "Current loss value: 111.15152\n",
      "Current loss value: 137.29744\n",
      "Current loss value: 147.12338\n",
      "Current loss value: 134.27487\n",
      "Current loss value: 153.07185\n",
      "Current loss value: 123.56514\n",
      "Current loss value: 167.43465\n",
      "Current loss value: 172.47592\n",
      "Current loss value: 183.3983\n",
      "Filter 49 processed in 12s\n",
      "Processing filter 50\n",
      "Current loss value: 112.77563\n",
      "Current loss value: 186.81172\n",
      "Current loss value: 232.13379\n",
      "Current loss value: 256.98306\n",
      "Current loss value: 289.39673\n",
      "Current loss value: 298.13226\n",
      "Current loss value: 328.768\n",
      "Current loss value: 350.9441\n",
      "Current loss value: 385.27682\n",
      "Current loss value: 415.56085\n",
      "Current loss value: 446.41376\n",
      "Current loss value: 476.53818\n",
      "Current loss value: 472.48453\n",
      "Current loss value: 504.8214\n",
      "Current loss value: 504.8022\n",
      "Current loss value: 550.5464\n",
      "Current loss value: 580.19495\n",
      "Current loss value: 607.7972\n",
      "Current loss value: 602.7621\n",
      "Current loss value: 662.04144\n",
      "Filter 50 processed in 13s\n",
      "Processing filter 51\n",
      "Current loss value: 0.0\n",
      "Filter 51 processed in 10s\n",
      "Processing filter 52\n",
      "Current loss value: 117.34087\n",
      "Current loss value: 160.97115\n",
      "Current loss value: 196.0529\n",
      "Current loss value: 234.78172\n",
      "Current loss value: 253.25504\n",
      "Current loss value: 276.91266\n",
      "Current loss value: 295.45972\n",
      "Current loss value: 309.6563\n",
      "Current loss value: 325.02655\n",
      "Current loss value: 324.04715\n",
      "Current loss value: 349.6232\n",
      "Current loss value: 379.1767\n",
      "Current loss value: 380.3137\n",
      "Current loss value: 360.86438\n",
      "Current loss value: 416.37155\n",
      "Current loss value: 429.95645\n",
      "Current loss value: 446.65195\n",
      "Current loss value: 471.35675\n",
      "Current loss value: 487.2133\n",
      "Current loss value: 507.78757\n",
      "Filter 52 processed in 13s\n",
      "Processing filter 53\n",
      "Current loss value: 201.42026\n",
      "Current loss value: 267.5096\n",
      "Current loss value: 324.64813\n",
      "Current loss value: 376.01117\n",
      "Current loss value: 409.4331\n",
      "Current loss value: 446.32162\n",
      "Current loss value: 484.06097\n",
      "Current loss value: 516.9557\n",
      "Current loss value: 512.4824\n",
      "Current loss value: 589.3062\n",
      "Current loss value: 584.28394\n",
      "Current loss value: 630.955\n",
      "Current loss value: 577.0813\n",
      "Current loss value: 676.4951\n",
      "Current loss value: 702.4718\n",
      "Current loss value: 725.30896\n",
      "Current loss value: 713.8275\n",
      "Current loss value: 751.9713\n",
      "Current loss value: 771.0362\n",
      "Current loss value: 774.33154\n",
      "Filter 53 processed in 14s\n",
      "Processing filter 54\n",
      "Current loss value: 78.85304\n",
      "Current loss value: 129.24316\n",
      "Current loss value: 163.76761\n",
      "Current loss value: 185.48799\n",
      "Current loss value: 191.74475\n",
      "Current loss value: 215.82768\n",
      "Current loss value: 233.23547\n",
      "Current loss value: 218.4257\n",
      "Current loss value: 258.37796\n",
      "Current loss value: 248.69997\n",
      "Current loss value: 254.3608\n",
      "Current loss value: 248.77686\n",
      "Current loss value: 283.0056\n",
      "Current loss value: 263.73825\n",
      "Current loss value: 302.86734\n",
      "Current loss value: 278.7572\n",
      "Current loss value: 323.53812\n",
      "Current loss value: 294.70023\n",
      "Current loss value: 337.68774\n",
      "Current loss value: 304.28726\n",
      "Filter 54 processed in 14s\n",
      "Processing filter 55\n",
      "Current loss value: 0.0\n",
      "Filter 55 processed in 12s\n",
      "Processing filter 56\n",
      "Current loss value: 0.0\n",
      "Filter 56 processed in 11s\n",
      "Processing filter 57\n",
      "Current loss value: 91.926216\n",
      "Current loss value: 141.55188\n",
      "Current loss value: 182.06923\n",
      "Current loss value: 203.51845\n",
      "Current loss value: 219.00296\n",
      "Current loss value: 214.96036\n",
      "Current loss value: 241.94064\n",
      "Current loss value: 244.65015\n",
      "Current loss value: 266.2005\n",
      "Current loss value: 290.19556\n",
      "Current loss value: 304.61996\n",
      "Current loss value: 282.7969\n",
      "Current loss value: 334.24362\n",
      "Current loss value: 339.64404\n",
      "Current loss value: 335.23883\n",
      "Current loss value: 349.69656\n",
      "Current loss value: 338.28247\n",
      "Current loss value: 369.2674\n",
      "Current loss value: 353.8662\n",
      "Current loss value: 387.1375\n",
      "Filter 57 processed in 15s\n",
      "Processing filter 58\n",
      "Current loss value: 106.2428\n",
      "Current loss value: 155.73991\n",
      "Current loss value: 196.12178\n",
      "Current loss value: 225.30429\n",
      "Current loss value: 239.82831\n",
      "Current loss value: 241.81897\n",
      "Current loss value: 296.66653\n",
      "Current loss value: 315.26804\n",
      "Current loss value: 314.3245\n",
      "Current loss value: 347.1626\n",
      "Current loss value: 378.3273\n",
      "Current loss value: 395.82538\n",
      "Current loss value: 389.20087\n",
      "Current loss value: 433.44244\n",
      "Current loss value: 405.67432\n",
      "Current loss value: 467.34488\n",
      "Current loss value: 436.1763\n",
      "Current loss value: 492.91956\n",
      "Current loss value: 461.2712\n",
      "Current loss value: 515.95715\n",
      "Filter 58 processed in 15s\n",
      "Processing filter 59\n",
      "Current loss value: 16.566921\n",
      "Current loss value: 36.630447\n",
      "Current loss value: 45.6643\n",
      "Current loss value: 58.79845\n",
      "Current loss value: 67.712814\n",
      "Current loss value: 69.15833\n",
      "Current loss value: 71.59236\n",
      "Current loss value: 81.090256\n",
      "Current loss value: 82.75691\n",
      "Current loss value: 85.42482\n",
      "Current loss value: 80.48011\n",
      "Current loss value: 97.86147\n",
      "Current loss value: 83.10559\n",
      "Current loss value: 101.562584\n",
      "Current loss value: 95.45189\n",
      "Current loss value: 101.86497\n",
      "Current loss value: 109.28509\n",
      "Current loss value: 98.840096\n",
      "Current loss value: 114.6958\n",
      "Current loss value: 100.62525\n",
      "Filter 59 processed in 15s\n",
      "Processing filter 60\n",
      "Current loss value: 0.0\n",
      "Filter 60 processed in 14s\n",
      "Processing filter 61\n",
      "Current loss value: 37.969093\n",
      "Current loss value: 73.54163\n",
      "Current loss value: 95.54491\n",
      "Current loss value: 112.70728\n",
      "Current loss value: 132.56506\n",
      "Current loss value: 157.99666\n",
      "Current loss value: 170.70451\n",
      "Current loss value: 188.09572\n",
      "Current loss value: 197.00514\n",
      "Current loss value: 197.26338\n",
      "Current loss value: 188.85945\n",
      "Current loss value: 221.17293\n",
      "Current loss value: 229.84987\n",
      "Current loss value: 233.96126\n",
      "Current loss value: 240.28545\n",
      "Current loss value: 228.31335\n",
      "Current loss value: 264.45636\n",
      "Current loss value: 274.0563\n",
      "Current loss value: 269.7675\n",
      "Current loss value: 290.39575\n",
      "Filter 61 processed in 19s\n",
      "Processing filter 62\n",
      "Current loss value: 0.0\n",
      "Filter 62 processed in 14s\n",
      "Processing filter 63\n",
      "Current loss value: 0.0\n",
      "Filter 63 processed in 14s\n",
      "Processing filter 64\n",
      "Current loss value: 30.711954\n",
      "Current loss value: 72.73139\n",
      "Current loss value: 105.925804\n",
      "Current loss value: 121.35047\n",
      "Current loss value: 123.19354\n",
      "Current loss value: 122.506004\n",
      "Current loss value: 143.60017\n",
      "Current loss value: 103.898125\n",
      "Current loss value: 154.21692\n",
      "Current loss value: 168.5948\n",
      "Current loss value: 146.86873\n",
      "Current loss value: 138.44592\n",
      "Current loss value: 170.28104\n",
      "Current loss value: 155.43385\n",
      "Current loss value: 183.14088\n",
      "Current loss value: 151.02603\n",
      "Current loss value: 193.65901\n",
      "Current loss value: 173.50227\n",
      "Current loss value: 195.45241\n",
      "Current loss value: 170.04205\n",
      "Filter 64 processed in 36s\n",
      "Processing filter 65\n",
      "Current loss value: 0.0\n",
      "Filter 65 processed in 135s\n",
      "Processing filter 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.0\n",
      "Filter 66 processed in 192s\n",
      "Processing filter 67\n",
      "Current loss value: 0.0\n",
      "Filter 67 processed in 189s\n",
      "Processing filter 68\n",
      "Current loss value: 95.017845\n",
      "Current loss value: 154.89677\n",
      "Current loss value: 222.40846\n",
      "Current loss value: 271.98935\n",
      "Current loss value: 322.71863\n",
      "Current loss value: 357.62064\n",
      "Current loss value: 396.28998\n",
      "Current loss value: 426.5182\n",
      "Current loss value: 445.028\n",
      "Current loss value: 490.5657\n",
      "Current loss value: 529.3679\n",
      "Current loss value: 530.3849\n",
      "Current loss value: 547.3529\n",
      "Current loss value: 535.46375\n",
      "Current loss value: 609.47565\n",
      "Current loss value: 570.8121\n",
      "Current loss value: 656.65686\n",
      "Current loss value: 634.9555\n",
      "Current loss value: 686.82446\n",
      "Current loss value: 624.18176\n",
      "Filter 68 processed in 149s\n",
      "Processing filter 69\n",
      "Current loss value: 116.209595\n",
      "Current loss value: 170.7856\n",
      "Current loss value: 212.1412\n",
      "Current loss value: 246.91621\n",
      "Current loss value: 249.91345\n",
      "Current loss value: 219.63097\n",
      "Current loss value: 279.39877\n",
      "Current loss value: 223.72981\n",
      "Current loss value: 282.0532\n",
      "Current loss value: 282.6105\n",
      "Current loss value: 311.10977\n",
      "Current loss value: 254.14348\n",
      "Current loss value: 332.38675\n",
      "Current loss value: 325.05334\n",
      "Current loss value: 345.04395\n",
      "Current loss value: 294.40323\n",
      "Current loss value: 364.74268\n",
      "Current loss value: 337.28333\n",
      "Current loss value: 377.47314\n",
      "Current loss value: 336.78943\n",
      "Filter 69 processed in 25s\n",
      "Processing filter 70\n",
      "Current loss value: 0.0\n",
      "Filter 70 processed in 16s\n",
      "Processing filter 71\n",
      "Current loss value: 110.17696\n",
      "Current loss value: 154.31969\n",
      "Current loss value: 185.31497\n",
      "Current loss value: 204.13557\n",
      "Current loss value: 223.92009\n",
      "Current loss value: 268.04642\n",
      "Current loss value: 305.35275\n",
      "Current loss value: 307.31396\n",
      "Current loss value: 314.00876\n",
      "Current loss value: 354.16296\n",
      "Current loss value: 373.7208\n",
      "Current loss value: 397.66745\n",
      "Current loss value: 393.4474\n",
      "Current loss value: 438.0184\n",
      "Current loss value: 418.29306\n",
      "Current loss value: 476.1404\n",
      "Current loss value: 423.47055\n",
      "Current loss value: 501.86215\n",
      "Current loss value: 507.2281\n",
      "Current loss value: 435.77225\n",
      "Filter 71 processed in 19s\n",
      "Processing filter 72\n",
      "Current loss value: 0.0\n",
      "Filter 72 processed in 17s\n",
      "Processing filter 73\n",
      "Current loss value: 78.61805\n",
      "Current loss value: 101.68104\n",
      "Current loss value: 122.01507\n",
      "Current loss value: 139.8158\n",
      "Current loss value: 152.494\n",
      "Current loss value: 158.03001\n",
      "Current loss value: 124.94278\n",
      "Current loss value: 171.23018\n",
      "Current loss value: 162.9046\n",
      "Current loss value: 175.9171\n",
      "Current loss value: 137.69624\n",
      "Current loss value: 191.17653\n",
      "Current loss value: 193.55106\n",
      "Current loss value: 201.49144\n",
      "Current loss value: 197.97302\n",
      "Current loss value: 215.86163\n",
      "Current loss value: 196.75452\n",
      "Current loss value: 217.65045\n",
      "Current loss value: 193.02376\n",
      "Current loss value: 232.8062\n",
      "Filter 73 processed in 21s\n",
      "Processing filter 74\n",
      "Current loss value: 0.0\n",
      "Filter 74 processed in 18s\n",
      "Processing filter 75\n",
      "Current loss value: 115.1872\n",
      "Current loss value: 148.38489\n",
      "Current loss value: 180.25894\n",
      "Current loss value: 225.15512\n",
      "Current loss value: 276.4219\n",
      "Current loss value: 318.5176\n",
      "Current loss value: 352.89496\n",
      "Current loss value: 386.37134\n",
      "Current loss value: 406.04617\n",
      "Current loss value: 435.97513\n",
      "Current loss value: 462.5797\n",
      "Current loss value: 501.8784\n",
      "Current loss value: 518.10535\n",
      "Current loss value: 527.2603\n",
      "Current loss value: 527.58716\n",
      "Current loss value: 565.10974\n",
      "Current loss value: 563.9308\n",
      "Current loss value: 570.94714\n",
      "Current loss value: 614.36285\n",
      "Current loss value: 620.4186\n",
      "Filter 75 processed in 21s\n",
      "Processing filter 76\n",
      "Current loss value: 0.0\n",
      "Filter 76 processed in 18s\n",
      "Processing filter 77\n",
      "Current loss value: 0.0\n",
      "Filter 77 processed in 19s\n",
      "Processing filter 78\n",
      "Current loss value: 0.0\n",
      "Filter 78 processed in 19s\n",
      "Processing filter 79\n",
      "Current loss value: 0.0\n",
      "Filter 79 processed in 20s\n",
      "Processing filter 80\n",
      "Current loss value: 78.77075\n",
      "Current loss value: 125.92055\n",
      "Current loss value: 158.8997\n",
      "Current loss value: 181.21115\n",
      "Current loss value: 180.5414\n",
      "Current loss value: 218.26024\n",
      "Current loss value: 232.65884\n",
      "Current loss value: 251.17934\n",
      "Current loss value: 235.8424\n",
      "Current loss value: 279.77673\n",
      "Current loss value: 282.21234\n",
      "Current loss value: 321.09723\n",
      "Current loss value: 326.43686\n",
      "Current loss value: 366.3705\n",
      "Current loss value: 365.36176\n",
      "Current loss value: 402.9741\n",
      "Current loss value: 424.83356\n",
      "Current loss value: 447.5913\n",
      "Current loss value: 474.6911\n",
      "Current loss value: 493.24103\n",
      "Filter 80 processed in 24s\n",
      "Processing filter 81\n",
      "Current loss value: 0.0\n",
      "Filter 81 processed in 21s\n",
      "Processing filter 82\n",
      "Current loss value: 0.0\n",
      "Filter 82 processed in 21s\n",
      "Processing filter 83\n",
      "Current loss value: 0.0\n",
      "Filter 83 processed in 22s\n",
      "Processing filter 84\n",
      "Current loss value: 0.0\n",
      "Filter 84 processed in 21s\n",
      "Processing filter 85\n",
      "Current loss value: 61.349335\n",
      "Current loss value: 86.1833\n",
      "Current loss value: 115.62369\n",
      "Current loss value: 141.35124\n",
      "Current loss value: 168.84178\n",
      "Current loss value: 183.31247\n",
      "Current loss value: 213.66818\n",
      "Current loss value: 236.72116\n",
      "Current loss value: 260.5523\n",
      "Current loss value: 278.75214\n",
      "Current loss value: 294.10757\n",
      "Current loss value: 311.16928\n",
      "Current loss value: 323.62363\n",
      "Current loss value: 338.8045\n",
      "Current loss value: 329.16763\n",
      "Current loss value: 357.22437\n",
      "Current loss value: 338.33032\n",
      "Current loss value: 370.34372\n",
      "Current loss value: 358.22583\n",
      "Current loss value: 404.716\n",
      "Filter 85 processed in 25s\n",
      "Processing filter 86\n",
      "Current loss value: 32.94157\n",
      "Current loss value: 80.97529\n",
      "Current loss value: 121.588005\n",
      "Current loss value: 160.3382\n",
      "Current loss value: 187.77771\n",
      "Current loss value: 212.38428\n",
      "Current loss value: 216.4511\n",
      "Current loss value: 238.66556\n",
      "Current loss value: 248.04031\n",
      "Current loss value: 265.85205\n",
      "Current loss value: 271.69543\n",
      "Current loss value: 292.257\n",
      "Current loss value: 279.63516\n",
      "Current loss value: 310.48926\n",
      "Current loss value: 291.34204\n",
      "Current loss value: 318.20087\n",
      "Current loss value: 320.07138\n",
      "Current loss value: 342.1314\n",
      "Current loss value: 341.1999\n",
      "Current loss value: 359.68973\n",
      "Filter 86 processed in 26s\n",
      "Processing filter 87\n",
      "Current loss value: 0.0\n",
      "Filter 87 processed in 22s\n",
      "Processing filter 88\n",
      "Current loss value: 0.0\n",
      "Filter 88 processed in 23s\n",
      "Processing filter 89\n",
      "Current loss value: 7.2439947\n",
      "Current loss value: 45.853535\n",
      "Current loss value: 85.48987\n",
      "Current loss value: 125.6404\n",
      "Current loss value: 165.95763\n",
      "Current loss value: 193.34302\n",
      "Current loss value: 215.78021\n",
      "Current loss value: 262.70544\n",
      "Current loss value: 283.734\n",
      "Current loss value: 330.23785\n",
      "Current loss value: 355.58386\n",
      "Current loss value: 377.6494\n",
      "Current loss value: 409.25467\n",
      "Current loss value: 439.6905\n",
      "Current loss value: 445.6174\n",
      "Current loss value: 477.92075\n",
      "Current loss value: 462.7823\n",
      "Current loss value: 545.5424\n",
      "Current loss value: 548.04004\n",
      "Current loss value: 555.3069\n",
      "Filter 89 processed in 26s\n",
      "Processing filter 90\n",
      "Current loss value: 0.0\n",
      "Filter 90 processed in 24s\n",
      "Processing filter 91\n",
      "Current loss value: 45.00192\n",
      "Current loss value: 97.2487\n",
      "Current loss value: 127.296646\n",
      "Current loss value: 150.49884\n",
      "Current loss value: 182.15578\n",
      "Current loss value: 209.37372\n",
      "Current loss value: 235.5022\n",
      "Current loss value: 252.40578\n",
      "Current loss value: 274.79926\n",
      "Current loss value: 307.24506\n",
      "Current loss value: 344.6829\n",
      "Current loss value: 388.53085\n",
      "Current loss value: 416.54947\n",
      "Current loss value: 446.57315\n",
      "Current loss value: 491.14774\n",
      "Current loss value: 537.7799\n",
      "Current loss value: 592.0403\n",
      "Current loss value: 642.9178\n",
      "Current loss value: 694.0559\n",
      "Current loss value: 751.63666\n",
      "Filter 91 processed in 27s\n",
      "Processing filter 92\n",
      "Current loss value: 0.0\n",
      "Filter 92 processed in 26s\n",
      "Processing filter 93\n",
      "Current loss value: 65.19785\n",
      "Current loss value: 112.300514\n",
      "Current loss value: 139.06789\n",
      "Current loss value: 160.47093\n",
      "Current loss value: 174.33986\n",
      "Current loss value: 191.12692\n",
      "Current loss value: 208.52446\n",
      "Current loss value: 219.88127\n",
      "Current loss value: 242.71935\n",
      "Current loss value: 254.14186\n",
      "Current loss value: 248.12839\n",
      "Current loss value: 280.88028\n",
      "Current loss value: 292.4183\n",
      "Current loss value: 302.43625\n",
      "Current loss value: 307.70648\n",
      "Current loss value: 342.79242\n",
      "Current loss value: 307.3535\n",
      "Current loss value: 362.12695\n",
      "Current loss value: 366.08365\n",
      "Current loss value: 376.8088\n",
      "Filter 93 processed in 28s\n",
      "Processing filter 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.0\n",
      "Filter 94 processed in 25s\n",
      "Processing filter 95\n",
      "Current loss value: 179.54373\n",
      "Current loss value: 229.87975\n",
      "Current loss value: 266.8705\n",
      "Current loss value: 296.08197\n",
      "Current loss value: 341.25897\n",
      "Current loss value: 388.273\n",
      "Current loss value: 419.09384\n",
      "Current loss value: 453.1794\n",
      "Current loss value: 474.8528\n",
      "Current loss value: 501.97922\n",
      "Current loss value: 515.8156\n",
      "Current loss value: 543.98535\n",
      "Current loss value: 572.5217\n",
      "Current loss value: 581.78674\n",
      "Current loss value: 632.21075\n",
      "Current loss value: 641.87695\n",
      "Current loss value: 672.8954\n",
      "Current loss value: 652.7241\n",
      "Current loss value: 707.6479\n",
      "Current loss value: 664.674\n",
      "Filter 95 processed in 29s\n",
      "Processing filter 96\n",
      "Current loss value: 0.0\n",
      "Filter 96 processed in 26s\n",
      "Processing filter 97\n",
      "Current loss value: 0.0\n",
      "Filter 97 processed in 27s\n",
      "Processing filter 98\n",
      "Current loss value: 86.67437\n",
      "Current loss value: 166.44048\n",
      "Current loss value: 235.13422\n",
      "Current loss value: 285.6938\n",
      "Current loss value: 355.509\n",
      "Current loss value: 416.02972\n",
      "Current loss value: 458.3165\n",
      "Current loss value: 504.04468\n",
      "Current loss value: 532.6744\n",
      "Current loss value: 534.7647\n",
      "Current loss value: 591.0992\n",
      "Current loss value: 590.41364\n",
      "Current loss value: 644.9713\n",
      "Current loss value: 656.02216\n",
      "Current loss value: 696.759\n",
      "Current loss value: 646.4322\n",
      "Current loss value: 760.46643\n",
      "Current loss value: 790.7911\n",
      "Current loss value: 775.9511\n",
      "Current loss value: 844.4814\n",
      "Filter 98 processed in 30s\n",
      "Processing filter 99\n",
      "Current loss value: 140.6652\n",
      "Current loss value: 181.46976\n",
      "Current loss value: 223.28067\n",
      "Current loss value: 264.08524\n",
      "Current loss value: 300.85452\n",
      "Current loss value: 337.53568\n",
      "Current loss value: 371.9253\n",
      "Current loss value: 410.7452\n",
      "Current loss value: 438.95694\n",
      "Current loss value: 461.4688\n",
      "Current loss value: 463.22104\n",
      "Current loss value: 525.66113\n",
      "Current loss value: 515.4854\n",
      "Current loss value: 575.71594\n",
      "Current loss value: 570.65063\n",
      "Current loss value: 649.26733\n",
      "Current loss value: 630.7987\n",
      "Current loss value: 697.7836\n",
      "Current loss value: 728.3966\n",
      "Current loss value: 737.6738\n",
      "Filter 99 processed in 31s\n",
      "Processing filter 100\n",
      "Current loss value: 0.0\n",
      "Filter 100 processed in 28s\n",
      "Processing filter 101\n",
      "Current loss value: 62.664104\n",
      "Current loss value: 111.86903\n",
      "Current loss value: 162.39156\n",
      "Current loss value: 173.1218\n",
      "Current loss value: 206.99234\n",
      "Current loss value: 265.97156\n",
      "Current loss value: 296.74655\n",
      "Current loss value: 297.14523\n",
      "Current loss value: 332.2147\n",
      "Current loss value: 350.98395\n",
      "Current loss value: 378.26263\n",
      "Current loss value: 387.08093\n",
      "Current loss value: 397.89056\n",
      "Current loss value: 420.46597\n",
      "Current loss value: 432.60422\n",
      "Current loss value: 445.5464\n",
      "Current loss value: 456.0334\n",
      "Current loss value: 454.27344\n",
      "Current loss value: 480.48657\n",
      "Current loss value: 499.55078\n",
      "Filter 101 processed in 34s\n",
      "Processing filter 102\n",
      "Current loss value: 0.0\n",
      "Filter 102 processed in 29s\n",
      "Processing filter 103\n",
      "Current loss value: 94.66521\n",
      "Current loss value: 129.92744\n",
      "Current loss value: 144.1077\n",
      "Current loss value: 155.2807\n",
      "Current loss value: 161.04967\n",
      "Current loss value: 181.48917\n",
      "Current loss value: 176.94644\n",
      "Current loss value: 192.56784\n",
      "Current loss value: 184.99991\n",
      "Current loss value: 213.31169\n",
      "Current loss value: 205.1778\n",
      "Current loss value: 226.47284\n",
      "Current loss value: 231.97206\n",
      "Current loss value: 254.57362\n",
      "Current loss value: 252.57689\n",
      "Current loss value: 273.64172\n",
      "Current loss value: 283.677\n",
      "Current loss value: 290.5246\n",
      "Current loss value: 284.34586\n",
      "Current loss value: 300.33734\n",
      "Filter 103 processed in 33s\n",
      "Processing filter 104\n",
      "Current loss value: 0.0\n",
      "Filter 104 processed in 30s\n",
      "Processing filter 105\n",
      "Current loss value: 0.0\n",
      "Filter 105 processed in 30s\n",
      "Processing filter 106\n",
      "Current loss value: 67.66684\n",
      "Current loss value: 127.06796\n",
      "Current loss value: 158.63838\n",
      "Current loss value: 173.19524\n",
      "Current loss value: 191.25194\n",
      "Current loss value: 191.72563\n",
      "Current loss value: 197.68938\n",
      "Current loss value: 223.17232\n",
      "Current loss value: 210.09695\n",
      "Current loss value: 248.04443\n",
      "Current loss value: 257.08167\n",
      "Current loss value: 285.37625\n",
      "Current loss value: 294.38492\n",
      "Current loss value: 318.0664\n",
      "Current loss value: 316.01422\n",
      "Current loss value: 358.66995\n",
      "Current loss value: 385.60617\n",
      "Current loss value: 406.72656\n",
      "Current loss value: 436.22443\n",
      "Current loss value: 483.68515\n",
      "Filter 106 processed in 35s\n",
      "Processing filter 107\n",
      "Current loss value: 5.33742\n",
      "Current loss value: 27.217102\n",
      "Current loss value: 43.783905\n",
      "Current loss value: 59.438828\n",
      "Current loss value: 54.608288\n",
      "Current loss value: 71.640366\n",
      "Current loss value: 72.60554\n",
      "Current loss value: 82.424324\n",
      "Current loss value: 60.132824\n",
      "Current loss value: 96.233635\n",
      "Current loss value: 91.91331\n",
      "Current loss value: 97.90554\n",
      "Current loss value: 80.19976\n",
      "Current loss value: 113.39216\n",
      "Current loss value: 108.31216\n",
      "Current loss value: 108.77266\n",
      "Current loss value: 104.60322\n",
      "Current loss value: 125.03984\n",
      "Current loss value: 116.87438\n",
      "Current loss value: 132.8621\n",
      "Filter 107 processed in 35s\n",
      "Processing filter 108\n",
      "Current loss value: 41.023033\n",
      "Current loss value: 94.13192\n",
      "Current loss value: 152.30003\n",
      "Current loss value: 194.27403\n",
      "Current loss value: 218.84895\n",
      "Current loss value: 241.57411\n",
      "Current loss value: 264.29117\n",
      "Current loss value: 273.01694\n",
      "Current loss value: 220.98631\n",
      "Current loss value: 296.9679\n",
      "Current loss value: 321.14175\n",
      "Current loss value: 284.57684\n",
      "Current loss value: 328.05966\n",
      "Current loss value: 298.89963\n",
      "Current loss value: 351.4368\n",
      "Current loss value: 302.1894\n",
      "Current loss value: 356.70447\n",
      "Current loss value: 332.05154\n",
      "Current loss value: 374.88077\n",
      "Current loss value: 334.74298\n",
      "Filter 108 processed in 36s\n",
      "Processing filter 109\n",
      "Current loss value: 96.81415\n",
      "Current loss value: 134.1347\n",
      "Current loss value: 156.26886\n",
      "Current loss value: 188.57483\n",
      "Current loss value: 214.51982\n",
      "Current loss value: 219.36118\n",
      "Current loss value: 208.42126\n",
      "Current loss value: 220.39531\n",
      "Current loss value: 237.79634\n",
      "Current loss value: 243.57022\n",
      "Current loss value: 239.06682\n",
      "Current loss value: 253.44681\n",
      "Current loss value: 270.1982\n",
      "Current loss value: 266.9248\n",
      "Current loss value: 275.14963\n",
      "Current loss value: 288.03778\n",
      "Current loss value: 293.76282\n",
      "Current loss value: 307.04144\n",
      "Current loss value: 302.98398\n",
      "Current loss value: 321.96667\n",
      "Filter 109 processed in 38s\n",
      "Processing filter 110\n",
      "Current loss value: 0.0\n",
      "Filter 110 processed in 34s\n",
      "Processing filter 111\n",
      "Current loss value: 0.0\n",
      "Filter 111 processed in 33s\n",
      "Processing filter 112\n",
      "Current loss value: 0.0\n",
      "Filter 112 processed in 34s\n",
      "Processing filter 113\n",
      "Current loss value: 107.7238\n",
      "Current loss value: 158.66643\n",
      "Current loss value: 204.55441\n",
      "Current loss value: 237.9738\n",
      "Current loss value: 238.75093\n",
      "Current loss value: 268.08173\n",
      "Current loss value: 290.01282\n",
      "Current loss value: 297.02118\n",
      "Current loss value: 310.7666\n",
      "Current loss value: 336.5188\n",
      "Current loss value: 347.6415\n",
      "Current loss value: 350.39893\n",
      "Current loss value: 375.97537\n",
      "Current loss value: 369.32288\n",
      "Current loss value: 402.17172\n",
      "Current loss value: 392.4554\n",
      "Current loss value: 427.96503\n",
      "Current loss value: 399.31866\n",
      "Current loss value: 438.20016\n",
      "Current loss value: 406.14975\n",
      "Filter 113 processed in 38s\n",
      "Processing filter 114\n",
      "Current loss value: 26.308762\n",
      "Current loss value: 71.16191\n",
      "Current loss value: 107.93619\n",
      "Current loss value: 141.80823\n",
      "Current loss value: 170.02985\n",
      "Current loss value: 193.55583\n",
      "Current loss value: 202.46992\n",
      "Current loss value: 211.64534\n",
      "Current loss value: 205.44765\n",
      "Current loss value: 232.45241\n",
      "Current loss value: 235.25652\n",
      "Current loss value: 271.33984\n",
      "Current loss value: 266.95404\n",
      "Current loss value: 308.19992\n",
      "Current loss value: 242.41585\n",
      "Current loss value: 332.6488\n",
      "Current loss value: 355.24307\n",
      "Current loss value: 360.02814\n",
      "Current loss value: 308.74353\n",
      "Current loss value: 389.5472\n",
      "Filter 114 processed in 38s\n",
      "Processing filter 115\n",
      "Current loss value: 0.0\n",
      "Filter 115 processed in 35s\n",
      "Processing filter 116\n",
      "Current loss value: 76.99265\n",
      "Current loss value: 115.9324\n",
      "Current loss value: 153.30423\n",
      "Current loss value: 167.12497\n",
      "Current loss value: 161.51953\n",
      "Current loss value: 203.59004\n",
      "Current loss value: 237.04541\n",
      "Current loss value: 263.03055\n",
      "Current loss value: 280.50122\n",
      "Current loss value: 243.30992\n",
      "Current loss value: 293.84357\n",
      "Current loss value: 263.2573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 318.2322\n",
      "Current loss value: 248.71498\n",
      "Current loss value: 340.5114\n",
      "Current loss value: 343.30124\n",
      "Current loss value: 337.898\n",
      "Current loss value: 313.6355\n",
      "Current loss value: 365.29514\n",
      "Current loss value: 349.00177\n",
      "Filter 116 processed in 39s\n",
      "Processing filter 117\n",
      "Current loss value: 231.40689\n",
      "Current loss value: 292.94733\n",
      "Current loss value: 334.85593\n",
      "Current loss value: 380.248\n",
      "Current loss value: 427.207\n",
      "Current loss value: 474.04578\n",
      "Current loss value: 529.7491\n",
      "Current loss value: 591.5555\n",
      "Current loss value: 639.39545\n",
      "Current loss value: 690.8031\n",
      "Current loss value: 746.8359\n",
      "Current loss value: 782.26587\n",
      "Current loss value: 811.92017\n",
      "Current loss value: 821.49207\n",
      "Current loss value: 880.7424\n",
      "Current loss value: 814.51105\n",
      "Current loss value: 936.73987\n",
      "Current loss value: 958.11646\n",
      "Current loss value: 987.38367\n",
      "Current loss value: 1018.29285\n",
      "Filter 117 processed in 40s\n",
      "Processing filter 118\n",
      "Current loss value: 1.9616426\n",
      "Current loss value: 45.101055\n",
      "Current loss value: 73.05492\n",
      "Current loss value: 86.24109\n",
      "Current loss value: 85.84387\n",
      "Current loss value: 100.16281\n",
      "Current loss value: 121.12045\n",
      "Current loss value: 135.99026\n",
      "Current loss value: 158.92622\n",
      "Current loss value: 153.99806\n",
      "Current loss value: 151.63068\n",
      "Current loss value: 173.68925\n",
      "Current loss value: 176.89941\n",
      "Current loss value: 188.39626\n",
      "Current loss value: 188.3392\n",
      "Current loss value: 200.2914\n",
      "Current loss value: 214.56853\n",
      "Current loss value: 206.18689\n",
      "Current loss value: 229.82614\n",
      "Current loss value: 218.55695\n",
      "Filter 118 processed in 41s\n",
      "Processing filter 119\n",
      "Current loss value: 0.0\n",
      "Filter 119 processed in 37s\n",
      "Processing filter 120\n",
      "Current loss value: 107.73703\n",
      "Current loss value: 133.81482\n",
      "Current loss value: 148.02277\n",
      "Current loss value: 159.07019\n",
      "Current loss value: 163.75256\n",
      "Current loss value: 181.6485\n",
      "Current loss value: 180.80403\n",
      "Current loss value: 204.7743\n",
      "Current loss value: 216.51703\n",
      "Current loss value: 240.6405\n",
      "Current loss value: 227.0723\n",
      "Current loss value: 271.10904\n",
      "Current loss value: 308.21478\n",
      "Current loss value: 355.07327\n",
      "Current loss value: 386.03906\n",
      "Current loss value: 391.3099\n",
      "Current loss value: 440.85962\n",
      "Current loss value: 448.32892\n",
      "Current loss value: 497.5936\n",
      "Current loss value: 483.72498\n",
      "Filter 120 processed in 42s\n",
      "Processing filter 121\n",
      "Current loss value: 167.12285\n",
      "Current loss value: 246.14868\n",
      "Current loss value: 310.14722\n",
      "Current loss value: 363.1062\n",
      "Current loss value: 411.9618\n",
      "Current loss value: 447.04227\n",
      "Current loss value: 445.09003\n",
      "Current loss value: 508.64658\n",
      "Current loss value: 511.1145\n",
      "Current loss value: 560.5507\n",
      "Current loss value: 539.277\n",
      "Current loss value: 602.78125\n",
      "Current loss value: 613.5834\n",
      "Current loss value: 652.9815\n",
      "Current loss value: 655.1384\n",
      "Current loss value: 674.2578\n",
      "Current loss value: 751.8531\n",
      "Current loss value: 781.28046\n",
      "Current loss value: 833.84393\n",
      "Current loss value: 892.00275\n",
      "Filter 121 processed in 42s\n",
      "Processing filter 122\n",
      "Current loss value: 0.0\n",
      "Filter 122 processed in 40s\n",
      "Processing filter 123\n",
      "Current loss value: 71.871414\n",
      "Current loss value: 122.26019\n",
      "Current loss value: 153.36841\n",
      "Current loss value: 179.58803\n",
      "Current loss value: 181.91414\n",
      "Current loss value: 203.07596\n",
      "Current loss value: 208.95534\n",
      "Current loss value: 231.89351\n",
      "Current loss value: 252.79996\n",
      "Current loss value: 273.18286\n",
      "Current loss value: 275.01102\n",
      "Current loss value: 242.66226\n",
      "Current loss value: 291.63934\n",
      "Current loss value: 281.3729\n",
      "Current loss value: 301.13986\n",
      "Current loss value: 308.96384\n",
      "Current loss value: 325.66293\n",
      "Current loss value: 330.40042\n",
      "Current loss value: 341.20364\n",
      "Current loss value: 336.23047\n",
      "Filter 123 processed in 44s\n",
      "Processing filter 124\n",
      "Current loss value: 187.13194\n",
      "Current loss value: 233.38156\n",
      "Current loss value: 271.9107\n",
      "Current loss value: 310.5251\n",
      "Current loss value: 339.42694\n",
      "Current loss value: 355.93964\n",
      "Current loss value: 327.8499\n",
      "Current loss value: 383.53305\n",
      "Current loss value: 345.3568\n",
      "Current loss value: 399.23474\n",
      "Current loss value: 372.92792\n",
      "Current loss value: 426.11008\n",
      "Current loss value: 347.01794\n",
      "Current loss value: 430.03604\n",
      "Current loss value: 434.91916\n",
      "Current loss value: 448.44498\n",
      "Current loss value: 429.4864\n",
      "Current loss value: 473.52814\n",
      "Current loss value: 461.63275\n",
      "Current loss value: 496.1471\n",
      "Filter 124 processed in 44s\n",
      "Processing filter 125\n",
      "Current loss value: 0.0\n",
      "Filter 125 processed in 41s\n",
      "Processing filter 126\n",
      "Current loss value: 51.42275\n",
      "Current loss value: 112.768585\n",
      "Current loss value: 163.45764\n",
      "Current loss value: 213.94853\n",
      "Current loss value: 258.84497\n",
      "Current loss value: 299.49884\n",
      "Current loss value: 334.22897\n",
      "Current loss value: 362.07233\n",
      "Current loss value: 391.99744\n",
      "Current loss value: 426.70593\n",
      "Current loss value: 431.36862\n",
      "Current loss value: 473.21307\n",
      "Current loss value: 440.36456\n",
      "Current loss value: 522.107\n",
      "Current loss value: 513.7035\n",
      "Current loss value: 554.73517\n",
      "Current loss value: 547.39557\n",
      "Current loss value: 604.46497\n",
      "Current loss value: 610.1179\n",
      "Current loss value: 646.2728\n",
      "Filter 126 processed in 46s\n",
      "Processing filter 127\n",
      "Current loss value: 108.52744\n",
      "Current loss value: 150.08057\n",
      "Current loss value: 194.5557\n",
      "Current loss value: 242.89243\n",
      "Current loss value: 286.12518\n",
      "Current loss value: 330.55362\n",
      "Current loss value: 354.80963\n",
      "Current loss value: 393.79437\n",
      "Current loss value: 429.67148\n",
      "Current loss value: 476.4139\n",
      "Current loss value: 509.03174\n",
      "Current loss value: 547.40045\n",
      "Current loss value: 588.401\n",
      "Current loss value: 635.4134\n",
      "Current loss value: 676.5141\n",
      "Current loss value: 706.5383\n",
      "Current loss value: 737.46735\n",
      "Current loss value: 782.1667\n",
      "Current loss value: 818.3607\n",
      "Current loss value: 808.538\n",
      "Filter 127 processed in 46s\n",
      "Processing filter 128\n",
      "Current loss value: 0.0\n",
      "Filter 128 processed in 43s\n",
      "Processing filter 129\n",
      "Current loss value: 35.741993\n",
      "Current loss value: 69.78864\n",
      "Current loss value: 104.47654\n",
      "Current loss value: 131.72498\n",
      "Current loss value: 139.13191\n",
      "Current loss value: 159.60623\n",
      "Current loss value: 177.79271\n",
      "Current loss value: 188.5127\n",
      "Current loss value: 207.37442\n",
      "Current loss value: 201.95586\n",
      "Current loss value: 229.31255\n",
      "Current loss value: 193.86186\n",
      "Current loss value: 253.30194\n",
      "Current loss value: 252.48235\n",
      "Current loss value: 277.90842\n",
      "Current loss value: 283.76245\n",
      "Current loss value: 285.57913\n",
      "Current loss value: 307.5037\n",
      "Current loss value: 297.56006\n",
      "Current loss value: 305.73068\n",
      "Filter 129 processed in 48s\n",
      "Processing filter 130\n",
      "Current loss value: 0.0\n",
      "Filter 130 processed in 44s\n",
      "Processing filter 131\n",
      "Current loss value: 0.0\n",
      "Filter 131 processed in 45s\n",
      "Processing filter 132\n",
      "Current loss value: 0.0\n",
      "Filter 132 processed in 47s\n",
      "Processing filter 133\n",
      "Current loss value: 0.0\n",
      "Filter 133 processed in 47s\n",
      "Processing filter 134\n",
      "Current loss value: 0.0\n",
      "Filter 134 processed in 48s\n",
      "Processing filter 135\n",
      "Current loss value: 0.0\n",
      "Filter 135 processed in 48s\n",
      "Processing filter 136\n",
      "Current loss value: 54.13556\n",
      "Current loss value: 114.02797\n",
      "Current loss value: 164.62253\n",
      "Current loss value: 194.76012\n",
      "Current loss value: 222.8284\n",
      "Current loss value: 220.50822\n",
      "Current loss value: 257.5378\n",
      "Current loss value: 246.49155\n",
      "Current loss value: 274.5926\n",
      "Current loss value: 281.8906\n",
      "Current loss value: 295.49063\n",
      "Current loss value: 302.2764\n",
      "Current loss value: 329.0346\n",
      "Current loss value: 332.13968\n",
      "Current loss value: 363.2582\n",
      "Current loss value: 389.86853\n",
      "Current loss value: 404.0396\n",
      "Current loss value: 372.5627\n",
      "Current loss value: 438.12918\n",
      "Current loss value: 460.39786\n",
      "Filter 136 processed in 52s\n",
      "Processing filter 137\n",
      "Current loss value: 0.0\n",
      "Filter 137 processed in 52s\n",
      "Processing filter 138\n",
      "Current loss value: 0.0\n",
      "Filter 138 processed in 51s\n",
      "Processing filter 139\n",
      "Current loss value: 0.0\n",
      "Filter 139 processed in 52s\n",
      "Processing filter 140\n",
      "Current loss value: 8.854893\n",
      "Current loss value: 53.898075\n",
      "Current loss value: 92.95113\n",
      "Current loss value: 111.92347\n",
      "Current loss value: 133.17004\n",
      "Current loss value: 160.60861\n",
      "Current loss value: 189.875\n",
      "Current loss value: 181.85074\n",
      "Current loss value: 217.16052\n",
      "Current loss value: 220.15292\n",
      "Current loss value: 240.0305\n",
      "Current loss value: 233.60974\n",
      "Current loss value: 270.4672\n",
      "Current loss value: 261.58633\n",
      "Current loss value: 292.5322\n",
      "Current loss value: 269.94098\n",
      "Current loss value: 313.83176\n",
      "Current loss value: 280.40887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 331.90958\n",
      "Current loss value: 332.7804\n",
      "Filter 140 processed in 55s\n",
      "Processing filter 141\n",
      "Current loss value: 120.20559\n",
      "Current loss value: 154.40169\n",
      "Current loss value: 184.39679\n",
      "Current loss value: 220.11449\n",
      "Current loss value: 250.16907\n",
      "Current loss value: 258.90396\n",
      "Current loss value: 282.89102\n",
      "Current loss value: 301.96558\n",
      "Current loss value: 317.9854\n",
      "Current loss value: 347.03195\n",
      "Current loss value: 371.8155\n",
      "Current loss value: 401.78787\n",
      "Current loss value: 420.1579\n",
      "Current loss value: 437.8661\n",
      "Current loss value: 462.7645\n",
      "Current loss value: 433.17905\n",
      "Current loss value: 497.1407\n",
      "Current loss value: 521.5351\n",
      "Current loss value: 534.8676\n",
      "Current loss value: 563.05725\n",
      "Filter 141 processed in 58s\n",
      "Processing filter 142\n",
      "Current loss value: 73.20593\n",
      "Current loss value: 123.578285\n",
      "Current loss value: 180.61801\n",
      "Current loss value: 232.84274\n",
      "Current loss value: 294.75626\n",
      "Current loss value: 332.41214\n",
      "Current loss value: 373.65308\n",
      "Current loss value: 415.04834\n",
      "Current loss value: 461.02032\n",
      "Current loss value: 510.93045\n",
      "Current loss value: 551.52405\n",
      "Current loss value: 594.0501\n",
      "Current loss value: 609.4213\n",
      "Current loss value: 542.25006\n",
      "Current loss value: 653.72955\n",
      "Current loss value: 680.83954\n",
      "Current loss value: 698.6088\n",
      "Current loss value: 692.4957\n",
      "Current loss value: 755.9948\n",
      "Current loss value: 723.8497\n",
      "Filter 142 processed in 57s\n",
      "Processing filter 143\n",
      "Current loss value: 59.5567\n",
      "Current loss value: 96.90743\n",
      "Current loss value: 152.67567\n",
      "Current loss value: 220.67111\n",
      "Current loss value: 279.96066\n",
      "Current loss value: 327.28033\n",
      "Current loss value: 376.99615\n",
      "Current loss value: 420.02847\n",
      "Current loss value: 457.71536\n",
      "Current loss value: 495.50925\n",
      "Current loss value: 532.86926\n",
      "Current loss value: 507.07428\n",
      "Current loss value: 560.9936\n",
      "Current loss value: 509.0471\n",
      "Current loss value: 612.0532\n",
      "Current loss value: 630.0692\n",
      "Current loss value: 650.08856\n",
      "Current loss value: 632.2001\n",
      "Current loss value: 691.3267\n",
      "Current loss value: 721.0375\n",
      "Filter 143 processed in 58s\n",
      "Processing filter 144\n",
      "Current loss value: 0.0\n",
      "Filter 144 processed in 54s\n",
      "Processing filter 145\n",
      "Current loss value: 0.0\n",
      "Filter 145 processed in 55s\n",
      "Processing filter 146\n",
      "Current loss value: 67.73134\n",
      "Current loss value: 113.66263\n",
      "Current loss value: 149.95288\n",
      "Current loss value: 182.6305\n",
      "Current loss value: 204.55313\n",
      "Current loss value: 174.64674\n",
      "Current loss value: 235.21548\n",
      "Current loss value: 247.46988\n",
      "Current loss value: 244.38797\n",
      "Current loss value: 267.8864\n",
      "Current loss value: 241.19215\n",
      "Current loss value: 289.08664\n",
      "Current loss value: 281.91263\n",
      "Current loss value: 301.5009\n",
      "Current loss value: 247.26396\n",
      "Current loss value: 326.7359\n",
      "Current loss value: 314.60413\n",
      "Current loss value: 331.7358\n",
      "Current loss value: 303.87375\n",
      "Current loss value: 354.78445\n",
      "Filter 146 processed in 60s\n",
      "Processing filter 147\n",
      "Current loss value: 0.0\n",
      "Filter 147 processed in 56s\n",
      "Processing filter 148\n",
      "Current loss value: 34.073246\n",
      "Current loss value: 79.11997\n",
      "Current loss value: 116.455605\n",
      "Current loss value: 146.61095\n",
      "Current loss value: 171.46254\n",
      "Current loss value: 200.11118\n",
      "Current loss value: 236.96707\n",
      "Current loss value: 270.11148\n",
      "Current loss value: 300.34445\n",
      "Current loss value: 313.72342\n",
      "Current loss value: 349.90073\n",
      "Current loss value: 379.07373\n",
      "Current loss value: 404.72363\n",
      "Current loss value: 432.43103\n",
      "Current loss value: 451.61792\n",
      "Current loss value: 475.17047\n",
      "Current loss value: 498.01462\n",
      "Current loss value: 513.3675\n",
      "Current loss value: 536.62634\n",
      "Current loss value: 553.33417\n",
      "Filter 148 processed in 63s\n",
      "Processing filter 149\n",
      "Current loss value: 58.872547\n",
      "Current loss value: 113.66001\n",
      "Current loss value: 163.84685\n",
      "Current loss value: 207.7128\n",
      "Current loss value: 228.57307\n",
      "Current loss value: 260.24796\n",
      "Current loss value: 258.4663\n",
      "Current loss value: 287.73062\n",
      "Current loss value: 293.93118\n",
      "Current loss value: 328.57446\n",
      "Current loss value: 333.74127\n",
      "Current loss value: 342.64484\n",
      "Current loss value: 356.89514\n",
      "Current loss value: 381.77695\n",
      "Current loss value: 376.90973\n",
      "Current loss value: 403.48965\n",
      "Current loss value: 409.32086\n",
      "Current loss value: 411.66052\n",
      "Current loss value: 432.43106\n",
      "Current loss value: 448.742\n",
      "Filter 149 processed in 64s\n",
      "Processing filter 150\n",
      "Current loss value: 0.0\n",
      "Filter 150 processed in 60s\n",
      "Processing filter 151\n",
      "Current loss value: 135.66354\n",
      "Current loss value: 196.56905\n",
      "Current loss value: 241.11171\n",
      "Current loss value: 265.67313\n",
      "Current loss value: 270.98602\n",
      "Current loss value: 295.13297\n",
      "Current loss value: 291.75894\n",
      "Current loss value: 331.4604\n",
      "Current loss value: 332.13565\n",
      "Current loss value: 352.5657\n",
      "Current loss value: 350.38773\n",
      "Current loss value: 365.48544\n",
      "Current loss value: 382.17874\n",
      "Current loss value: 401.019\n",
      "Current loss value: 385.07175\n",
      "Current loss value: 412.6287\n",
      "Current loss value: 429.16168\n",
      "Current loss value: 448.26\n",
      "Current loss value: 426.1824\n",
      "Current loss value: 470.13275\n",
      "Filter 151 processed in 65s\n",
      "Processing filter 152\n",
      "Current loss value: 66.95083\n",
      "Current loss value: 100.80345\n",
      "Current loss value: 127.057785\n",
      "Current loss value: 149.34552\n",
      "Current loss value: 173.28456\n",
      "Current loss value: 208.85362\n",
      "Current loss value: 244.02429\n",
      "Current loss value: 283.76547\n",
      "Current loss value: 303.76575\n",
      "Current loss value: 338.6938\n",
      "Current loss value: 361.88696\n",
      "Current loss value: 376.9998\n",
      "Current loss value: 389.4036\n",
      "Current loss value: 415.91647\n",
      "Current loss value: 431.42245\n",
      "Current loss value: 469.53943\n",
      "Current loss value: 476.79294\n",
      "Current loss value: 516.654\n",
      "Current loss value: 550.1893\n",
      "Current loss value: 556.19226\n",
      "Filter 152 processed in 67s\n",
      "Processing filter 153\n",
      "Current loss value: 0.0\n",
      "Filter 153 processed in 62s\n",
      "Processing filter 154\n",
      "Current loss value: 8.859192\n",
      "Current loss value: 44.880703\n",
      "Current loss value: 82.19708\n",
      "Current loss value: 115.22407\n",
      "Current loss value: 142.82964\n",
      "Current loss value: 153.99973\n",
      "Current loss value: 195.55946\n",
      "Current loss value: 210.83405\n",
      "Current loss value: 174.40868\n",
      "Current loss value: 203.8922\n",
      "Current loss value: 230.34921\n",
      "Current loss value: 222.90335\n",
      "Current loss value: 242.90192\n",
      "Current loss value: 263.08197\n",
      "Current loss value: 272.38403\n",
      "Current loss value: 283.2642\n",
      "Current loss value: 282.6769\n",
      "Current loss value: 302.2529\n",
      "Current loss value: 286.57745\n",
      "Current loss value: 337.79538\n",
      "Filter 154 processed in 69s\n",
      "Processing filter 155\n",
      "Current loss value: 68.87768\n",
      "Current loss value: 105.68803\n",
      "Current loss value: 139.84297\n",
      "Current loss value: 176.34773\n",
      "Current loss value: 203.6643\n",
      "Current loss value: 226.92078\n",
      "Current loss value: 246.50636\n",
      "Current loss value: 263.15118\n",
      "Current loss value: 274.45987\n",
      "Current loss value: 287.61337\n",
      "Current loss value: 301.66208\n",
      "Current loss value: 304.3873\n",
      "Current loss value: 322.73462\n",
      "Current loss value: 335.1185\n",
      "Current loss value: 356.7864\n",
      "Current loss value: 332.1229\n",
      "Current loss value: 378.71933\n",
      "Current loss value: 360.16873\n",
      "Current loss value: 397.60355\n",
      "Current loss value: 407.87448\n",
      "Filter 155 processed in 69s\n",
      "Processing filter 156\n",
      "Current loss value: 0.0\n",
      "Filter 156 processed in 66s\n",
      "Processing filter 157\n",
      "Current loss value: 0.0\n",
      "Filter 157 processed in 66s\n",
      "Processing filter 158\n",
      "Current loss value: 33.81364\n",
      "Current loss value: 70.86455\n",
      "Current loss value: 99.662735\n",
      "Current loss value: 132.17303\n",
      "Current loss value: 151.48904\n",
      "Current loss value: 167.95192\n",
      "Current loss value: 159.32814\n",
      "Current loss value: 190.60187\n",
      "Current loss value: 176.66566\n",
      "Current loss value: 211.20111\n",
      "Current loss value: 200.85542\n",
      "Current loss value: 227.69403\n",
      "Current loss value: 224.19913\n",
      "Current loss value: 239.2957\n",
      "Current loss value: 251.90366\n",
      "Current loss value: 255.42935\n",
      "Current loss value: 266.8304\n",
      "Current loss value: 263.97263\n",
      "Current loss value: 285.23987\n",
      "Current loss value: 265.51062\n",
      "Filter 158 processed in 73s\n",
      "Processing filter 159\n",
      "Current loss value: 0.0\n",
      "Filter 159 processed in 71s\n",
      "Processing filter 160\n",
      "Current loss value: 39.714207\n",
      "Current loss value: 77.23958\n",
      "Current loss value: 111.95168\n",
      "Current loss value: 134.78886\n",
      "Current loss value: 184.355\n",
      "Current loss value: 230.49094\n",
      "Current loss value: 247.1815\n",
      "Current loss value: 286.21295\n",
      "Current loss value: 273.2025\n",
      "Current loss value: 283.4059\n",
      "Current loss value: 315.8612\n",
      "Current loss value: 306.9056\n",
      "Current loss value: 355.08844\n",
      "Current loss value: 363.34866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 359.44904\n",
      "Current loss value: 373.42093\n",
      "Current loss value: 394.50742\n",
      "Current loss value: 407.85068\n",
      "Current loss value: 420.1857\n",
      "Current loss value: 442.8701\n",
      "Filter 160 processed in 73s\n",
      "Processing filter 161\n",
      "Current loss value: 0.0\n",
      "Filter 161 processed in 68s\n",
      "Processing filter 162\n",
      "Current loss value: 0.0\n",
      "Filter 162 processed in 71s\n",
      "Processing filter 163\n",
      "Current loss value: 0.0\n",
      "Filter 163 processed in 71s\n",
      "Processing filter 164\n",
      "Current loss value: 167.49823\n",
      "Current loss value: 210.1942\n",
      "Current loss value: 246.5052\n",
      "Current loss value: 291.1174\n",
      "Current loss value: 335.3228\n",
      "Current loss value: 375.64792\n",
      "Current loss value: 405.0337\n",
      "Current loss value: 434.7218\n",
      "Current loss value: 459.86478\n",
      "Current loss value: 474.18494\n",
      "Current loss value: 478.9291\n",
      "Current loss value: 499.74268\n",
      "Current loss value: 512.26483\n",
      "Current loss value: 553.0912\n",
      "Current loss value: 575.11053\n",
      "Current loss value: 602.41785\n",
      "Current loss value: 643.9313\n",
      "Current loss value: 670.1152\n",
      "Current loss value: 722.178\n",
      "Current loss value: 761.49896\n",
      "Filter 164 processed in 79s\n",
      "Processing filter 165\n",
      "Current loss value: 8.215179\n",
      "Current loss value: 48.595917\n",
      "Current loss value: 85.34465\n",
      "Current loss value: 107.15406\n",
      "Current loss value: 118.31465\n",
      "Current loss value: 142.24889\n",
      "Current loss value: 160.2149\n",
      "Current loss value: 185.62746\n",
      "Current loss value: 213.14088\n",
      "Current loss value: 234.11942\n",
      "Current loss value: 249.24283\n",
      "Current loss value: 276.23236\n",
      "Current loss value: 281.693\n",
      "Current loss value: 319.59415\n",
      "Current loss value: 322.54483\n",
      "Current loss value: 352.47214\n",
      "Current loss value: 339.24832\n",
      "Current loss value: 394.04202\n",
      "Current loss value: 398.7827\n",
      "Current loss value: 422.92465\n",
      "Filter 165 processed in 79s\n",
      "Processing filter 166\n",
      "Current loss value: 0.0\n",
      "Filter 166 processed in 76s\n",
      "Processing filter 167\n",
      "Current loss value: 37.503025\n",
      "Current loss value: 78.42419\n",
      "Current loss value: 112.427155\n",
      "Current loss value: 131.81647\n",
      "Current loss value: 144.10289\n",
      "Current loss value: 141.986\n",
      "Current loss value: 158.06212\n",
      "Current loss value: 169.5754\n",
      "Current loss value: 170.31363\n",
      "Current loss value: 147.46452\n",
      "Current loss value: 177.13678\n",
      "Current loss value: 188.3533\n",
      "Current loss value: 194.97656\n",
      "Current loss value: 199.49445\n",
      "Current loss value: 194.40019\n",
      "Current loss value: 207.26903\n",
      "Current loss value: 218.89612\n",
      "Current loss value: 228.62204\n",
      "Current loss value: 221.87921\n",
      "Current loss value: 220.91093\n",
      "Filter 167 processed in 81s\n",
      "Processing filter 168\n",
      "Current loss value: 0.0\n",
      "Filter 168 processed in 76s\n",
      "Processing filter 169\n",
      "Current loss value: 29.617907\n",
      "Current loss value: 70.173195\n",
      "Current loss value: 109.132744\n",
      "Current loss value: 136.62819\n",
      "Current loss value: 151.29265\n",
      "Current loss value: 154.13202\n",
      "Current loss value: 174.55865\n",
      "Current loss value: 174.2884\n",
      "Current loss value: 201.74408\n",
      "Current loss value: 222.73888\n",
      "Current loss value: 225.1957\n",
      "Current loss value: 237.03534\n",
      "Current loss value: 264.45242\n",
      "Current loss value: 277.05716\n",
      "Current loss value: 279.305\n",
      "Current loss value: 310.458\n",
      "Current loss value: 309.21448\n",
      "Current loss value: 334.51013\n",
      "Current loss value: 331.85718\n",
      "Current loss value: 340.9943\n",
      "Filter 169 processed in 83s\n",
      "Processing filter 170\n",
      "Current loss value: 0.0\n",
      "Filter 170 processed in 77s\n",
      "Processing filter 171\n",
      "Current loss value: 82.88468\n",
      "Current loss value: 124.08313\n",
      "Current loss value: 159.5794\n",
      "Current loss value: 183.7967\n",
      "Current loss value: 201.43631\n",
      "Current loss value: 189.0262\n",
      "Current loss value: 223.17236\n",
      "Current loss value: 225.15422\n",
      "Current loss value: 250.9056\n",
      "Current loss value: 249.09612\n",
      "Current loss value: 274.25974\n",
      "Current loss value: 253.03542\n",
      "Current loss value: 290.7206\n",
      "Current loss value: 283.01123\n",
      "Current loss value: 309.3986\n",
      "Current loss value: 323.6699\n",
      "Current loss value: 322.36035\n",
      "Current loss value: 303.189\n",
      "Current loss value: 356.81635\n",
      "Current loss value: 330.2505\n",
      "Filter 171 processed in 85s\n",
      "Processing filter 172\n",
      "Current loss value: 0.0\n",
      "Filter 172 processed in 91s\n",
      "Processing filter 173\n",
      "Current loss value: 0.0\n",
      "Filter 173 processed in 81s\n",
      "Processing filter 174\n",
      "Current loss value: 0.0\n",
      "Filter 174 processed in 83s\n",
      "Processing filter 175\n",
      "Current loss value: 70.12869\n",
      "Current loss value: 119.55411\n",
      "Current loss value: 148.02646\n",
      "Current loss value: 162.37436\n",
      "Current loss value: 190.68953\n",
      "Current loss value: 190.12753\n",
      "Current loss value: 209.93517\n",
      "Current loss value: 174.25487\n",
      "Current loss value: 232.52055\n",
      "Current loss value: 215.89941\n",
      "Current loss value: 244.85461\n",
      "Current loss value: 231.39413\n",
      "Current loss value: 269.75607\n",
      "Current loss value: 260.5325\n",
      "Current loss value: 295.40057\n",
      "Current loss value: 290.7348\n",
      "Current loss value: 312.91455\n",
      "Current loss value: 301.85547\n",
      "Current loss value: 336.23383\n",
      "Current loss value: 322.62894\n",
      "Filter 175 processed in 89s\n",
      "Processing filter 176\n",
      "Current loss value: 64.428604\n",
      "Current loss value: 128.45726\n",
      "Current loss value: 158.62387\n",
      "Current loss value: 189.36575\n",
      "Current loss value: 191.53131\n",
      "Current loss value: 205.99187\n",
      "Current loss value: 203.0176\n",
      "Current loss value: 240.82639\n",
      "Current loss value: 238.35306\n",
      "Current loss value: 270.83148\n",
      "Current loss value: 249.44714\n",
      "Current loss value: 290.57895\n",
      "Current loss value: 285.34695\n",
      "Current loss value: 310.00876\n",
      "Current loss value: 282.5423\n",
      "Current loss value: 330.22217\n",
      "Current loss value: 345.637\n",
      "Current loss value: 356.17023\n",
      "Current loss value: 340.69714\n",
      "Current loss value: 366.46396\n",
      "Filter 176 processed in 90s\n",
      "Processing filter 177\n",
      "Current loss value: 16.53599\n",
      "Current loss value: 61.382626\n",
      "Current loss value: 101.37494\n",
      "Current loss value: 129.4477\n",
      "Current loss value: 154.79787\n",
      "Current loss value: 181.05133\n",
      "Current loss value: 200.57349\n",
      "Current loss value: 232.54\n",
      "Current loss value: 252.09435\n",
      "Current loss value: 255.88934\n",
      "Current loss value: 241.42717\n",
      "Current loss value: 295.0268\n",
      "Current loss value: 268.6578\n",
      "Current loss value: 321.68652\n",
      "Current loss value: 303.49612\n",
      "Current loss value: 352.77716\n",
      "Current loss value: 340.108\n",
      "Current loss value: 365.77698\n",
      "Current loss value: 345.7223\n",
      "Current loss value: 391.3431\n",
      "Filter 177 processed in 91s\n",
      "Processing filter 178\n",
      "Current loss value: 0.0\n",
      "Filter 178 processed in 86s\n",
      "Processing filter 179\n",
      "Current loss value: 83.806366\n",
      "Current loss value: 131.1325\n",
      "Current loss value: 159.47763\n",
      "Current loss value: 186.60976\n",
      "Current loss value: 206.3431\n",
      "Current loss value: 231.10948\n",
      "Current loss value: 260.5539\n",
      "Current loss value: 264.2586\n",
      "Current loss value: 282.2834\n",
      "Current loss value: 291.72763\n",
      "Current loss value: 329.1105\n",
      "Current loss value: 359.8008\n",
      "Current loss value: 384.0188\n",
      "Current loss value: 398.8396\n",
      "Current loss value: 416.86948\n",
      "Current loss value: 334.21103\n",
      "Current loss value: 451.46066\n",
      "Current loss value: 448.5294\n",
      "Current loss value: 430.63452\n",
      "Current loss value: 497.51837\n",
      "Filter 179 processed in 93s\n",
      "Processing filter 180\n",
      "Current loss value: 0.0\n",
      "Filter 180 processed in 89s\n",
      "Processing filter 181\n",
      "Current loss value: 94.6957\n",
      "Current loss value: 176.92693\n",
      "Current loss value: 254.47906\n",
      "Current loss value: 314.70425\n",
      "Current loss value: 363.1473\n",
      "Current loss value: 394.99338\n",
      "Current loss value: 422.6766\n",
      "Current loss value: 469.0547\n",
      "Current loss value: 519.1554\n",
      "Current loss value: 556.3415\n",
      "Current loss value: 593.95325\n",
      "Current loss value: 623.3761\n",
      "Current loss value: 655.4533\n",
      "Current loss value: 683.30176\n",
      "Current loss value: 698.3369\n",
      "Current loss value: 668.2556\n",
      "Current loss value: 749.1513\n",
      "Current loss value: 747.6991\n",
      "Current loss value: 810.78625\n",
      "Current loss value: 833.4809\n",
      "Filter 181 processed in 96s\n",
      "Processing filter 182\n",
      "Current loss value: 0.0\n",
      "Filter 182 processed in 89s\n",
      "Processing filter 183\n",
      "Current loss value: 0.0\n",
      "Filter 183 processed in 92s\n",
      "Processing filter 184\n",
      "Current loss value: 43.59807\n",
      "Current loss value: 92.701126\n",
      "Current loss value: 146.04767\n",
      "Current loss value: 178.49759\n",
      "Current loss value: 200.06795\n",
      "Current loss value: 221.6247\n",
      "Current loss value: 237.71225\n",
      "Current loss value: 271.86212\n",
      "Current loss value: 303.1032\n",
      "Current loss value: 342.09103\n",
      "Current loss value: 380.11978\n",
      "Current loss value: 416.60947\n",
      "Current loss value: 453.2744\n",
      "Current loss value: 495.83963\n",
      "Current loss value: 544.1381\n",
      "Current loss value: 587.14136\n",
      "Current loss value: 638.38837\n",
      "Current loss value: 679.0095\n",
      "Current loss value: 724.7635\n",
      "Current loss value: 759.8649\n",
      "Filter 184 processed in 100s\n",
      "Processing filter 185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.0\n",
      "Filter 185 processed in 92s\n",
      "Processing filter 186\n",
      "Current loss value: 0.0\n",
      "Filter 186 processed in 98s\n",
      "Processing filter 187\n",
      "Current loss value: 0.0\n",
      "Filter 187 processed in 94s\n",
      "Processing filter 188\n",
      "Current loss value: 130.7109\n",
      "Current loss value: 169.07202\n",
      "Current loss value: 190.12549\n",
      "Current loss value: 190.989\n",
      "Current loss value: 219.20735\n",
      "Current loss value: 238.52376\n",
      "Current loss value: 250.94946\n",
      "Current loss value: 266.37885\n",
      "Current loss value: 277.6544\n",
      "Current loss value: 296.01962\n",
      "Current loss value: 323.48026\n",
      "Current loss value: 339.66354\n",
      "Current loss value: 335.83252\n",
      "Current loss value: 321.06445\n",
      "Current loss value: 384.04654\n",
      "Current loss value: 406.05667\n",
      "Current loss value: 435.51135\n",
      "Current loss value: 456.7121\n",
      "Current loss value: 489.13202\n",
      "Current loss value: 511.38248\n",
      "Filter 188 processed in 105s\n",
      "Processing filter 189\n",
      "Current loss value: 0.0\n",
      "Filter 189 processed in 104s\n",
      "Processing filter 190\n",
      "Current loss value: 0.0\n",
      "Filter 190 processed in 97s\n",
      "Processing filter 191\n",
      "Current loss value: 0.0\n",
      "Filter 191 processed in 100s\n",
      "Processing filter 192\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "slice index 192 of dimension 3 out of bounds. for 'strided_slice_192' (op: 'StridedSlice') with input shapes: [?,?,?,192], [4], [4], [4] and with computed input tensors: input[1] = <0 0 0 192>, input[2] = <0 0 0 193>, input[3] = <1 1 1 1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index 192 of dimension 3 out of bounds. for 'strided_slice_192' (op: 'StridedSlice') with input shapes: [?,?,?,192], [4], [4], [4] and with computed input tensors: input[1] = <0 0 0 192>, input[2] = <0 0 0 193>, input[3] = <1 1 1 1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4ef25458729e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# we compute the gradient of the input picture wrt this loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m    758\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m   9732\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9733\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9734\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   9735\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9736\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3290\u001b[0m           op_def=op_def)\n\u001b[0;32m   3291\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3292\u001b[1;33m                              compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3330\u001b[0m     \u001b[1;31m# compute_shapes argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3332\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3333\u001b[0m     \u001b[1;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2467\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2469\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2470\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2398\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2399\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2401\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: slice index 192 of dimension 3 out of bounds. for 'strided_slice_192' (op: 'StridedSlice') with input shapes: [?,?,?,192], [4], [4], [4] and with computed input tensors: input[1] = <0 0 0 192>, input[2] = <0 0 0 193>, input[3] = <1 1 1 1>."
     ]
    }
   ],
   "source": [
    "kept_filters = []\n",
    "for filter_index in range(200):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 8\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the result to disk\n",
    "save_img('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "imshow(stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
