{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplying two matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf handle:  Tensor(\"MatMul:0\", shape=(10, 10), dtype=float32)\n",
      "actual matrix product  [[ 0.51359665  2.872926    4.546303    3.3981328   0.75388277  0.30101556\n",
      "   3.2338479   3.7337859   0.65348697 -0.64218354]\n",
      " [ 2.2632537  -2.7244818  -2.7225685  -2.1101034  -7.6224623  -4.579688\n",
      "   5.278821    0.61067617  0.0966301  -0.30087176]\n",
      " [ 3.9118042   4.208037    9.509781    6.4187527   5.7446055   3.2369027\n",
      "   9.91751     3.0986564  -1.9311206   8.5680685 ]\n",
      " [ 1.0557564   0.24406815  0.6063826   0.32787287  1.2544739  -4.111596\n",
      "  -0.9338187   4.2576733   0.6308284  -0.8230331 ]\n",
      " [-1.4215841   1.2676978  -6.1712785   1.374303   -3.4528756  -5.5349593\n",
      "  -0.570045    1.2239252   4.885189   -7.6845975 ]\n",
      " [-0.21696456  1.5884198   0.06801377  2.7661834   0.43136168 -0.42676637\n",
      "   2.4129086   1.1250029   1.5321157   3.7543886 ]\n",
      " [ 1.7517694   1.2805418  -1.9844838   0.28716955 -4.3618317  -1.612256\n",
      "   8.58833     0.05009779  0.2663226   1.2788968 ]\n",
      " [ 2.413901    1.4912431   2.7859695   0.3492698   0.7844099   0.6657739\n",
      "  -2.3356369  -2.7567658  -1.8397819   1.8665226 ]\n",
      " [ 0.76694477  1.645885   -4.2591686  -6.887944    1.0301559  -0.23668051\n",
      "  -2.4334745  -2.6498396  -6.587099    3.9961786 ]\n",
      " [ 0.04536352  0.94362575 -3.6944776  -2.853848    1.8406882   2.9591193\n",
      "   7.0602     -4.441708   -0.3682375   1.0491055 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal([10,15])\n",
    "y = tf.random_normal([15,10])\n",
    "\n",
    "z = tf.matmul(x,y)\n",
    "\n",
    "print(\"tf handle: \",z)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(z)\n",
    "    print(\"actual matrix product \", res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a quadratic function \n",
    "\n",
    "We learn the function based on the input sample points using Stochastic Gradient Descent. \n",
    "\n",
    "First we define the model with placeholder input & outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders are used to feed values from python to TensorFlow ops. We define\n",
    "# two placeholders, one for input feature x, and one for output y.\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Assuming we know that the desired function is quadratic in nature, i.e., a polynomial of 2nd degree, we\n",
    "# allocate a vector of size 3 to hold the coefficients. The variable will be\n",
    "# automatically initialized with random noise.\n",
    "w = tf.get_variable(\"w\", shape=[3, 1])\n",
    "\n",
    "# We define yhat to be our estimate of y.\n",
    "f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)\n",
    "yhat = tf.squeeze(tf.matmul(f, w), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add the necessary ingredients for performing stochastic descent (i.e., defining the optimization & the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The loss is defined to be the l2 distance between our estimate of y and its\n",
    "# true value. We also added a shrinkage term, to ensure the resulting weights\n",
    "# would be small.\n",
    "loss = tf.nn.l2_loss(yhat - y) + 0.1 * tf.nn.l2_loss(w)\n",
    "\n",
    "# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.\n",
    "train_op = tf.train.AdamOptimizer(0.1).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate input data by sampling from some quadratic function \n",
    "# here we are trying to learn the function:\n",
    "# f(x) = ax^2 + bx + c\n",
    "def generate_quadratic(a,b,c):\n",
    "    x_val = np.random.uniform(-10.0, 10.0, size=100)\n",
    "    y_val = a * np.square(x_val) + b * x_val + c\n",
    "    return x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.0162432],\n",
      "       [ 2.0024037],\n",
      "       [13.997231 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "b = 2\n",
    "c = 15\n",
    "with tf.Session() as sess:\n",
    "    # Since we are using variables we first need to initialize them.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(1000): # Try replacing 1k with 10k. \n",
    "        x_val, y_val = generate_quadratic(a,b,c)\n",
    "        _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})\n",
    "        #print(loss_val)\n",
    "    print(sess.run([w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns shape (static if available or dynamic) of the tensor\n",
    "def get_shape(tensor):\n",
    "  static_shape = tensor.shape.as_list()\n",
    "  dynamic_shape = tf.unstack(tf.shape(tensor))\n",
    "  dims = [s[1] if s[0] is None else s[0]\n",
    "          for s in zip(static_shape, dynamic_shape)]\n",
    "  return dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshapes the tensor by collapsing any number of dimensions\n",
    "# this comes in very handy if you are dealing with input images that can be of multiple dimensions\n",
    "# and are usually collapsed into 2 dimensions.\n",
    "def reshape(tensor, dims_list):\n",
    "  shape = get_shape(tensor)\n",
    "  dims_prod = []\n",
    "  for dims in dims_list:\n",
    "    if isinstance(dims, int):\n",
    "      dims_prod.append(shape[dims])\n",
    "    elif all([isinstance(shape[d], int) for d in dims]):\n",
    "      dims_prod.append(np.prod([shape[d] for d in dims]))\n",
    "    else:\n",
    "      dims_prod.append(tf.prod([shape[d] for d in dims]))\n",
    "  tensor = tf.reshape(tensor, dims_prod)\n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources:\n",
    "\n",
    "[EffectiveTensorflow](https://github.com/vahidk/EffectiveTensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
